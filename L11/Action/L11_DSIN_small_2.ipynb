{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "matrix = pd.read_csv('./matrix.csv')\n",
    "#print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(8):\n",
    "    temp_1 = matrix['session_'+ str(num) + '_merchant_id']\n",
    "    temp_2 = matrix['session_'+ str(num) + '_action_type']\n",
    "    temp_3 = 'session_'+ str(num) + '_merchant_id'\n",
    "    temp_4 = 'session_'+ str(num) + '_action_type'\n",
    "    for num_1 in range(len(temp_1)):\n",
    "        temp = temp_1[num_1]\n",
    "        #print(temp)\n",
    "        merchant_id_list = temp[1:-1].strip().split(', ')\n",
    "        #print(merchant_id_list)\n",
    "        matrix.at[num_1,temp_3] = merchant_id_list\n",
    "\n",
    "    for num_2 in range(len(temp_2)):\n",
    "        temp = temp_2[num_2]\n",
    "        action_type_list = temp[1:-1].strip().split(', ')\n",
    "        matrix.at[num_2, temp_4] = action_type_list\n",
    "\n",
    "#print(matrix['session_0_merchant_id'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=500\n",
    "\n",
    "#print(matrix['session_0_merchant_id'][0])\n",
    "#print(type(matrix['session_0_merchant_id'][0]))\n",
    "#print(matrix['session_0_merchant_id'])\n",
    "\n",
    "for num in range(8):\n",
    "    temp_1 = matrix['session_'+ str(num) + '_merchant_id']\n",
    "    temp_2 = matrix['session_'+ str(num) + '_action_type']\n",
    "    temp_3 = 'session_'+ str(num) + '_merchant_id'\n",
    "    temp_4 = 'session_'+ str(num) + '_action_type'\n",
    "    for merchant_id_num1 in range(len(temp_1)):\n",
    "        temp_5 = temp_1[merchant_id_num1]\n",
    "        #print(temp_5)\n",
    "        if len(temp_5)>M:\n",
    "            matrix.at[merchant_id_num1,temp_3] = temp_5[:M]\n",
    "        else:\n",
    "            while len(temp_5)<M:\n",
    "                temp_5.append('0')\n",
    "            matrix.at[merchant_id_num1,temp_3] = temp_5\n",
    "    for action_type_num1 in range(len(temp_1)):\n",
    "        temp_6 = temp_2[action_type_num1]\n",
    "        if len(temp_6)>M:\n",
    "            matrix.at[action_type_num1,temp_4] = temp_6[:M]\n",
    "        else:\n",
    "            while len(temp_6)<M:\n",
    "                temp_6.append('0')\n",
    "            matrix.at[action_type_num1,temp_4] = temp_6            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matrix = matrix.drop('merchant_id_y',axis = 1)\n",
    "matrix = matrix.drop('action_type',axis = 1)\n",
    "matrix = matrix.drop('time_stamp',axis = 1)\n",
    "matrix = matrix.rename(columns={'session_0_merchant_id':'sess_0_merchant_id'})\n",
    "matrix = matrix.rename(columns={'session_0_action_type':'sess_0_action_type'})\n",
    "matrix = matrix.rename(columns={'session_1_merchant_id':'sess_1_merchant_id'})\n",
    "matrix = matrix.rename(columns={'session_1_action_type':'sess_1_action_type'})\n",
    "matrix = matrix.rename(columns={'session_2_merchant_id':'sess_2_merchant_id'})\n",
    "matrix = matrix.rename(columns={'session_2_action_type':'sess_2_action_type'})\n",
    "matrix = matrix.rename(columns={'session_3_merchant_id':'sess_3_merchant_id'})\n",
    "matrix = matrix.rename(columns={'session_3_action_type':'sess_3_action_type'})\n",
    "matrix = matrix.rename(columns={'session_4_merchant_id':'sess_4_merchant_id'})\n",
    "matrix = matrix.rename(columns={'session_4_action_type':'sess_4_action_type'})\n",
    "matrix = matrix.rename(columns={'session_5_merchant_id':'sess_5_merchant_id'})\n",
    "matrix = matrix.rename(columns={'session_5_action_type':'sess_5_action_type'})\n",
    "matrix = matrix.rename(columns={'session_6_merchant_id':'sess_6_merchant_id'})\n",
    "matrix = matrix.rename(columns={'session_6_action_type':'sess_6_action_type'})\n",
    "matrix = matrix.rename(columns={'session_7_merchant_id':'sess_7_merchant_id'})\n",
    "matrix = matrix.rename(columns={'session_7_action_type':'sess_7_action_type'})\n",
    "matrix = matrix.rename(columns={'merchant_id_x':'merchant_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = matrix.drop('sess_3_merchant_id',axis = 1)\n",
    "matrix = matrix.drop('sess_3_action_type',axis = 1)\n",
    "matrix = matrix.drop('sess_4_merchant_id',axis = 1)\n",
    "matrix = matrix.drop('sess_4_action_type',axis = 1)\n",
    "matrix = matrix.drop('sess_5_merchant_id',axis = 1)\n",
    "matrix = matrix.drop('sess_5_action_type',axis = 1)\n",
    "matrix = matrix.drop('sess_6_merchant_id',axis = 1)\n",
    "matrix = matrix.drop('sess_6_action_type',axis = 1)\n",
    "matrix = matrix.drop('sess_7_merchant_id',axis = 1)\n",
    "matrix = matrix.drop('sess_7_action_type',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for num in range(len(matrix)):\n",
    "    for num_1 in range(3):\n",
    "        temp_1 = matrix['sess_'+ str(num_1) + '_merchant_id']\n",
    "        temp_2 = temp_1[num]\n",
    "        temp_3 = temp_2[0]\n",
    "        if temp_3 == '0':\n",
    "            matrix.loc[num,'sess_length'] = num_1\n",
    "            break\n",
    "        else:\n",
    "            if num_1 == 2 :\n",
    "                matrix.loc[num,'sess_length'] = 3\n",
    "\n",
    "#print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割训练数据和测试数据\n",
    "train_data = matrix[matrix['origin'] == 'train'].drop(['origin'], axis=1)\n",
    "test_data = matrix[matrix['origin'] == 'test'].drop(['label', 'origin'], axis=1)\n",
    "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TAOXUEJIE-PSD\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\TAOXUEJIE-PSD\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\TAOXUEJIE-PSD\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\TAOXUEJIE-PSD\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\TAOXUEJIE-PSD\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\TAOXUEJIE-PSD\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\TAOXUEJIE-PSD\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\TAOXUEJIE-PSD\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\TAOXUEJIE-PSD\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\TAOXUEJIE-PSD\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\TAOXUEJIE-PSD\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\TAOXUEJIE-PSD\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M= 500\n"
     ]
    }
   ],
   "source": [
    "# 使用DSIN模型\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from deepctr.inputs import SparseFeat,VarLenSparseFeat,DenseFeat,get_feature_names\n",
    "from deepctr.models import DIN, DIEN, DSIN\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_X['action_type']=3\n",
    "feature_columns = []\n",
    "for column in train_X.columns:\n",
    "    session_text = 'sess'\n",
    "    if session_text not in column :\n",
    "        #print(column)\n",
    "        num = train_X[column].nunique()\n",
    "        if num > 10000:\n",
    "            dim = 10\n",
    "        else:\n",
    "            if num > 1000:\n",
    "                dim = 8\n",
    "            else:\n",
    "                dim = 4\n",
    "        #print(num)\n",
    "        if column  == 'user_id':\n",
    "            feature_columns += [SparseFeat(column, 19111+1, embedding_dim=dim, use_hash=True)]\n",
    "        elif column  == 'merchant_id':\n",
    "            feature_columns += [SparseFeat(column, 4994+1, embedding_dim=dim, use_hash=True)]\n",
    "        elif column  == 'action_type':\n",
    "            feature_columns += [SparseFeat(column, 4+1, embedding_dim=dim, use_hash=True)]\n",
    "        else:\n",
    "            feature_columns += [DenseFeat(column, 1)]\n",
    "\n",
    "print('M=', M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxlen为历史信息的长度，vocabulary_size为onehot的长度\n",
    "feature_columns += [VarLenSparseFeat(SparseFeat('sess_0_merchant_id', vocabulary_size=19111 + 1, embedding_dim=8, use_hash=True, embedding_name='merchant_id'),maxlen=M),\n",
    "                    VarLenSparseFeat(SparseFeat('sess_0_action_type', vocabulary_size=4 + 1, embedding_dim=4, use_hash=True, embedding_name='cate_id'),maxlen=M)]\n",
    "feature_columns += [VarLenSparseFeat(SparseFeat('sess_1_merchant_id', vocabulary_size=19111 + 1, embedding_dim=8, use_hash=True, embedding_name='merchant_id'),maxlen=M),\n",
    "                    VarLenSparseFeat(SparseFeat('sess_1_action_type', vocabulary_size=4 + 1, embedding_dim=4, use_hash=True, embedding_name='cate_id'),maxlen=M)]\n",
    "feature_columns += [VarLenSparseFeat(SparseFeat('sess_2_merchant_id', vocabulary_size=19111 + 1, embedding_dim=8, use_hash=True, embedding_name='merchant_id'),maxlen=M),\n",
    "                    VarLenSparseFeat(SparseFeat('sess_2_action_type', vocabulary_size=4 + 1, embedding_dim=4, use_hash=True, embedding_name='cate_id'),maxlen=M)]\n",
    "#feature_columns += [VarLenSparseFeat(SparseFeat('sess_3_merchant_id', vocabulary_size=19111 + 1, embedding_dim=8, use_hash=True, embedding_name='merchant_id'),maxlen=M),\n",
    "                    #VarLenSparseFeat(SparseFeat('sess_3_action_type', vocabulary_size=4 + 1, embedding_dim=4, use_hash=True, embedding_name='cate_id'),maxlen=M)]\n",
    "#feature_columns += [VarLenSparseFeat(SparseFeat('sess_4_merchant_id', vocabulary_size=19111 + 1, embedding_dim=8, use_hash=True, embedding_name='merchant_id'),maxlen=M),\n",
    "                    #VarLenSparseFeat(SparseFeat('sess_4_action_type', vocabulary_size=4 + 1, embedding_dim=4, use_hash=True, embedding_name='cate_id'),maxlen=M)]\n",
    "#feature_columns += [VarLenSparseFeat(SparseFeat('sess_5_merchant_id', vocabulary_size=19111 + 1, embedding_dim=8, use_hash=True, embedding_name='merchant_id'),maxlen=M),\n",
    "                    #VarLenSparseFeat(SparseFeat('sess_5_action_type', vocabulary_size=4 + 1, embedding_dim=4, use_hash=True, embedding_name='cate_id'),maxlen=M)]\n",
    "#feature_columns += [VarLenSparseFeat(SparseFeat('sess_6_merchant_id', vocabulary_size=19111 + 1, embedding_dim=8, use_hash=True, embedding_name='merchant_id'),maxlen=M),\n",
    "                    #VarLenSparseFeat(SparseFeat('sess_6_action_type', vocabulary_size=4 + 1, embedding_dim=4, use_hash=True, embedding_name='cate_id'),maxlen=M)]\n",
    "#feature_columns += [VarLenSparseFeat(SparseFeat('sess_7_merchant_id', vocabulary_size=19111 + 1, embedding_dim=8, use_hash=True, embedding_name='merchant_id'),maxlen=M),\n",
    "                    #VarLenSparseFeat(SparseFeat('sess_7_action_type', vocabulary_size=4 + 1, embedding_dim=4, use_hash=True, embedding_name='cate_id'),maxlen=M)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17837/17837 [00:00<00:00, 2230384.89it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 17837/17837 [00:00<00:00, 2473265.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 17837/17837 [00:00<00:00, 872230.19it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 17837/17837 [00:00<00:00, 1502979.30it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 17837/17837 [00:00<00:00, 3559341.57it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 17837/17837 [00:00<00:00, 1691510.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14269 samples, validate on 3568 samples\n",
      "Epoch 1/3\n",
      "14269/14269 [==============================] - 1938s 136ms/sample - loss: 0.2270 - binary_crossentropy: 0.2270 - val_loss: 0.2299 - val_binary_crossentropy: 0.2299\n",
      "Epoch 2/3\n",
      "14269/14269 [==============================] - 1908s 134ms/sample - loss: 0.2246 - binary_crossentropy: 0.2246 - val_loss: 0.2283 - val_binary_crossentropy: 0.2283\n",
      "Epoch 3/3\n",
      "14269/14269 [==============================] - 1911s 134ms/sample - loss: 0.2245 - binary_crossentropy: 0.2245 - val_loss: 0.2293 - val_binary_crossentropy: 0.2293\n"
     ]
    }
   ],
   "source": [
    "hist_features=['merchant_id','action_type']\n",
    "# 使用DSIN模型\n",
    "model=DSIN(feature_columns, hist_features, sess_max_count=3, att_embedding_size=3, att_head_num=4)\n",
    "# 使用Adam优化器，二分类的交叉熵\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['binary_crossentropy'])\n",
    "\n",
    "# 组装train_model_input，得到feature names，将train_X转换为字典格式\n",
    "feature_names=list(train_X.columns)\n",
    "train_model_input = {name:train_X[name].values for name in feature_names}\n",
    "# histroy输入必须是二维数组\n",
    "from tqdm import tqdm\n",
    "for fea in ['sess_0_merchant_id','sess_0_action_type',\n",
    "           'sess_1_merchant_id','sess_1_action_type',\n",
    "           'sess_2_merchant_id','sess_2_action_type']:\n",
    "           #'sess_3_merchant_id','sess_3_action_type',\n",
    "           #'sess_4_merchant_id','sess_4_action_type',\n",
    "           #'sess_5_merchant_id','sess_5_action_type',\n",
    "           #'sess_6_merchant_id','sess_6_action_type',\n",
    "           #'sess_7_merchant_id','sess_7_action_type']:\n",
    "    l = []\n",
    "    for i in tqdm(train_model_input[fea]):\n",
    "        l.append(i)\n",
    "    train_model_input[fea]=np.array(l)\n",
    "history = model.fit(train_model_input, train_y, verbose=True, epochs=3, validation_split=0.2,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 6056/6056 [00:00<00:00, 2024444.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 6056/6056 [00:00<00:00, 326449.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 6056/6056 [00:00<00:00, 2149141.64it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 6056/6056 [00:00<00:00, 2101837.40it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 6056/6056 [00:00<00:00, 2499331.40it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 6056/6056 [00:00<00:00, 1926777.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# 转换test__model_input\n",
    "test_data['action_type']=3\n",
    "test_model_input = {name:test_data[name].values for name in feature_names}\n",
    "from tqdm import tqdm\n",
    "for fea in ['sess_0_merchant_id','sess_0_action_type',\n",
    "           'sess_1_merchant_id','sess_1_action_type',\n",
    "           'sess_2_merchant_id','sess_2_action_type']:\n",
    "    l = []\n",
    "    for i in tqdm(test_model_input[fea]):\n",
    "        l.append(i)\n",
    "    test_model_input[fea]=np.array(l)\n",
    "\n",
    "\n",
    "# 得到预测结果\n",
    "prob = model.predict(test_model_input)\n",
    "submission = pd.read_csv('./data_format1_small/test.csv')\n",
    "submission['prob'] = prob\n",
    "submission.to_csv('prediction.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
