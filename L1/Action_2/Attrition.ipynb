{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user_id  Attrition\n",
      "0        442   0.048477\n",
      "1       1091   0.013149\n",
      "2        981   0.523220\n",
      "3        785   0.028260\n",
      "4       1332   0.916846\n",
      "..       ...        ...\n",
      "289     1439   0.018231\n",
      "290      481   0.010532\n",
      "291      124   0.619353\n",
      "292      198   0.021148\n",
      "293     1229   0.040336\n",
      "\n",
      "[294 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 数据加载\n",
    "train_data = pd.read_csv('./Attrition_train.csv')\n",
    "test_data = pd.read_csv('./Attrition_test.csv')\n",
    "test_data_1 = pd.read_csv('./Attrition_test.csv')\n",
    "\n",
    "# 数据处理\n",
    "train_data = train_data.drop(columns=['user_id','EmployeeCount','EmployeeNumber','Over18','StandardHours'])\n",
    "train_data = train_data.drop(columns=['DailyRate','HourlyRate','MonthlyRate'])\n",
    "test_data = test_data.drop(columns=['user_id','EmployeeCount','EmployeeNumber','Over18','StandardHours'])\n",
    "test_data = test_data.drop(columns=['DailyRate','HourlyRate','MonthlyRate'])\n",
    "\n",
    "train_data.loc[train_data.Attrition == 'Yes','Attrition'] = 1\n",
    "train_data.loc[train_data.Attrition == 'No','Attrition'] = 0\n",
    "\n",
    "train_data['NumCompaniesWorkedPerYear'] = train_data.apply(lambda x: x['NumCompaniesWorked'] / (x['TotalWorkingYears']+1), axis=1)\n",
    "train_data = train_data.drop(columns=['NumCompaniesWorked','TotalWorkingYears'])\n",
    "test_data['NumCompaniesWorkedPerYear'] = test_data.apply(lambda x: x['NumCompaniesWorked'] / (x['TotalWorkingYears']+1), axis=1)\n",
    "test_data = test_data.drop(columns=['NumCompaniesWorked','TotalWorkingYears'])\n",
    "\n",
    "'''\n",
    "#探索离散参数与离职的关系\n",
    "for i in train_data.columns:\n",
    "    if train_data[i].dtype == 'O':\n",
    "        print(i + ':')\n",
    "        print((train_data[train_data['Attrition'] == 1][i].value_counts()/train_data[i].value_counts()).sort_values(ascending=False))\n",
    "        print('-----------------------')\n",
    "'''\n",
    "\n",
    "'''\n",
    "#探索年龄与离职的关系\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x='Age', y='Attrition', data = train_data )\n",
    "'''\n",
    "\n",
    "#重新划分年龄标识\n",
    "def resetAge(name):\n",
    "    if (name >= 18) & (name < 22)  & (name == 58):\n",
    "        return 1\n",
    "    elif (name == 54) & (name == 57) & (name > 58) :\n",
    "        return 0\n",
    "    else:\n",
    "        return 2\n",
    "'''\n",
    "#探索月薪与离职的关系\n",
    "facet = sns.FacetGrid(train_data,hue = 'Attrition' ,aspect=3)\n",
    "facet.map(sns.kdeplot,'MonthlyIncome',shade = True)\n",
    "facet.set(xlim=(0,train_data['MonthlyIncome'].max()))\n",
    "facet.add_legend()\n",
    "'''\n",
    "#重新划分月薪标识\n",
    "def resetSalary(s):\n",
    "    if s>0 & s<3725:\n",
    "        return 0\n",
    "    elif s>=3725 & s<8500:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "'''\n",
    "#探索涨薪幅度与离职的关系\n",
    "plt.figure(figsize=(14,5))\n",
    "sns.barplot(x='PercentSalaryHike', y='Attrition', data = train_data , palette = 'Set2')\n",
    "'''\n",
    "def resetPerHike(s):\n",
    "    if (s >= 22 & s < 25) | (s == 11):\n",
    "        return 0\n",
    "    elif (s >= 12 & s < 14) | (s == 17):\n",
    "        return 1\n",
    "    elif (s >24):\n",
    "        return 3\n",
    "    else:\n",
    "        return 2\n",
    "'''\n",
    "#探索每年就职公司数与离职的关系\n",
    "facet = sns.FacetGrid(train_data,hue = 'Attrition' ,aspect=3)\n",
    "facet.map(sns.kdeplot,'NumCompaniesWorkedPerYear',shade = True)\n",
    "facet.set(xlim=(0,train_data['NumCompaniesWorkedPerYear'].max()))\n",
    "facet.add_legend()\n",
    "'''\n",
    "#重新划分就职公司数标识\n",
    "def resetWorkingCompanyNum(s):\n",
    "    if (s > 0) & (s < 0.34):\n",
    "        return 0\n",
    "    elif (s >= 0.34) & (s < 1.25):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "'''\n",
    "#探索在本公司工作年限与离职的关系\n",
    "plt.figure(figsize=(14,5))\n",
    "sns.barplot(x='YearsAtCompany', y='Attrition', data = train_data , palette = 'Set2')\n",
    "'''\n",
    "def resetYearsAtCompany(s):\n",
    "    if s==40 :\n",
    "        return 0\n",
    "    elif s==23 | (s>=31 & s<33):\n",
    "        return 1\n",
    "    elif s==12 | s==15 | s==16 | (s>=21 & s<23)| (s>=24 & s<31) | (s>=34 & s<38) | s>40 :\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "#重定义数据\n",
    "train_data['Age'] = train_data['Age'].apply(resetAge)\n",
    "train_data['PercentSalaryHike'] = train_data['PercentSalaryHike'].apply(resetPerHike)\n",
    "train_data['MonthlyIncome'] = train_data['MonthlyIncome'].apply(resetSalary)\n",
    "train_data['NumCompaniesWorkedPerYear'] = train_data['NumCompaniesWorkedPerYear'].apply(resetWorkingCompanyNum)\n",
    "train_data['YearsAtCompany'] = train_data['YearsAtCompany'].apply(resetYearsAtCompany)\n",
    "test_data['Age'] = test_data['Age'].apply(resetAge)\n",
    "test_data['PercentSalaryHike'] = test_data['PercentSalaryHike'].apply(resetPerHike)\n",
    "test_data['MonthlyIncome'] = test_data['MonthlyIncome'].apply(resetSalary)\n",
    "test_data['NumCompaniesWorkedPerYear'] = test_data['NumCompaniesWorkedPerYear'].apply(resetWorkingCompanyNum)\n",
    "test_data['YearsAtCompany'] = test_data['YearsAtCompany'].apply(resetYearsAtCompany)\n",
    "\n",
    "#将离散数据进行one-hot编码(训练集)\n",
    "cata_result = pd.DataFrame()\n",
    "for i in train_data.columns:\n",
    "    if train_data[i].dtype == 'O':\n",
    "        cata = pd.DataFrame()\n",
    "        cata = pd.get_dummies(train_data[i],prefix=i)\n",
    "        cata_result = pd.concat([cata_result,cata],axis=1)\n",
    "\n",
    "for i in train_data.columns:\n",
    "    if train_data[i].dtype == 'O':\n",
    "        train_data = train_data.drop(i,axis=1)\n",
    "\n",
    "#将离散数据进行one-hot编码(测试集)\n",
    "cata_result_test = pd.DataFrame()\n",
    "for i in test_data.columns:\n",
    "    if test_data[i].dtype == 'O':\n",
    "        cata_test = pd.DataFrame()\n",
    "        cata_test = pd.get_dummies(test_data[i],prefix=i)\n",
    "        cata_result_test = pd.concat([cata_result_test,cata_test],axis=1)\n",
    "\n",
    "for i in test_data.columns:\n",
    "    if test_data[i].dtype == 'O':\n",
    "        test_data = test_data.drop(i,axis=1)\n",
    "        \n",
    "train_data = pd.concat([train_data,cata_result],axis=1)\n",
    "train_features = train_data.drop(columns=['Attrition'])\n",
    "train_labels = train_data['Attrition']\n",
    "test_data = pd.concat([test_data,cata_result_test],axis=1)\n",
    "\n",
    "'''\n",
    "#分割训练集与测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_features.astype(np.float64),\n",
    "    train_labels.astype(np.float64), train_size=0.8, test_size=0.2,random_state=42)\n",
    "\n",
    "#利用TPOT选择模型\n",
    "tpot = TPOTClassifier(generations=5, population_size=20, verbosity=2)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "#tpot.export('tpot_Attribute_pipeline_1.py')\n",
    "'''\n",
    "#利用模型进行预测\n",
    "model = GradientBoostingClassifier(learning_rate=1.0, max_depth=1, max_features=0.7500000000000001, min_samples_leaf=16, min_samples_split=6, n_estimators=100, subsample=1.0)\n",
    "\n",
    "model.fit(train_features, train_labels)\n",
    "pred_labels_test = model.predict_proba(test_data)\n",
    "#print(pred_labels_test)\n",
    "\n",
    "predict_y = []\n",
    "for i in range(len(pred_labels_test)):\n",
    "    predict_y.append(pred_labels_test[i][1]/(pred_labels_test[i][0]+pred_labels_test[i][1]))\n",
    "\n",
    "pred_test = test_data_1['user_id'].tolist()\n",
    "pred_result = pd.DataFrame({'user_id':pred_test,'Attrition':predict_y})\n",
    "print(pred_result)\n",
    "\n",
    "#pred_result.to_csv('./result_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
